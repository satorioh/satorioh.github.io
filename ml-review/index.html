<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"roubin.me","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1.数据从哪里来？如何构建数据集？123456781.现场自行采集（成本比较高）2.甲方提供3.网络下载现成的4.企业真实的数据（商业价值最高）5.购买（合法购买和使用，千万不要侵犯别人的隐私）6.爬虫（合法使用，不要侵犯别人的隐私）数据分门别类,进行标注">
<meta property="og:type" content="article">
<meta property="og:title" content="ML&#x2F;DL复习">
<meta property="og:url" content="https://roubin.me/ml-review/index.html">
<meta property="og:site_name" content="肉饼博客">
<meta property="og:description" content="1.数据从哪里来？如何构建数据集？123456781.现场自行采集（成本比较高）2.甲方提供3.网络下载现成的4.企业真实的数据（商业价值最高）5.购买（合法购买和使用，千万不要侵犯别人的隐私）6.爬虫（合法使用，不要侵犯别人的隐私）数据分门别类,进行标注">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://roubin.me/images/ml_review_mse_loss.png">
<meta property="article:published_time" content="2024-05-21T01:14:43.000Z">
<meta property="article:modified_time" content="2024-05-24T07:20:28.845Z">
<meta property="article:author" content="roubin">
<meta property="article:tag" content="ml">
<meta property="article:tag" content="dl">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://roubin.me/images/ml_review_mse_loss.png">

<link rel="canonical" href="https://roubin.me/ml-review/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>ML/DL复习 | 肉饼博客</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b55ece62ebeb2e72a8efe3f8b5b43960";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">肉饼博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Talk is cheap. Show me the code.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://roubin.me/ml-review/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="roubin">
      <meta itemprop="description" content="芝兰其室，金石其心<br/>仁义为友，道德为师">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="肉饼博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML/DL复习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-05-21 09:14:43" itemprop="dateCreated datePublished" datetime="2024-05-21T09:14:43+08:00">2024-05-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-05-24 15:20:28" itemprop="dateModified" datetime="2024-05-24T15:20:28+08:00">2024-05-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/ml-review/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="ml-review/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h4 id="1-数据从哪里来？如何构建数据集？"><a href="#1-数据从哪里来？如何构建数据集？" class="headerlink" title="1.数据从哪里来？如何构建数据集？"></a>1.数据从哪里来？如何构建数据集？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.现场自行采集（成本比较高）</span><br><span class="line">2.甲方提供</span><br><span class="line">3.网络下载现成的</span><br><span class="line">4.企业真实的数据（商业价值最高）</span><br><span class="line">5.购买（合法购买和使用，千万不要侵犯别人的隐私）</span><br><span class="line">6.爬虫（合法使用，不要侵犯别人的隐私）</span><br><span class="line"></span><br><span class="line">数据分门别类,进行标注</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<h4 id="2-数据量多大？"><a href="#2-数据量多大？" class="headerlink" title="2.数据量多大？"></a>2.数据量多大？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">深度学习越多越好</span><br><span class="line">最起码每个类别数百级单位</span><br></pre></td></tr></table></figure>

<h4 id="3-数据量不够如何处理？"><a href="#3-数据量不够如何处理？" class="headerlink" title="3.数据量不够如何处理？"></a>3.数据量不够如何处理？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">数据增强</span><br><span class="line">CV: 旋转、缩放、裁剪、调整色调、亮度、对比度、添加噪声。。。</span><br><span class="line">NLP: 近义词替换、文本摘要。。。。</span><br></pre></td></tr></table></figure>

<h4 id="4-采用的模型是什么？为什么使用YOLOv8？"><a href="#4-采用的模型是什么？为什么使用YOLOv8？" class="headerlink" title="4.采用的模型是什么？为什么使用YOLOv8？"></a>4.采用的模型是什么？为什么使用YOLOv8？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">效果</span><br><span class="line">  依据：根据实际需求，以及项目的难易程度，选择现有的、经典的、成熟的模型，更换成自己的数据集，进行训练，并调参</span><br><span class="line">  </span><br><span class="line">  如果不确定模型，选择多个模型，进行对比，选择效果最好的</span><br><span class="line">  </span><br><span class="line">  在有些情况下，需要多个模型配合使用，发挥各自的特长</span><br><span class="line"></span><br><span class="line">YOLOv8优势</span><br><span class="line">    1.保持高精度的同时，具有更快的推理速度，适合实时检测</span><br><span class="line">    2.多模型尺寸、多任务能力</span><br><span class="line">    3.友好的文档、API、社区支持</span><br></pre></td></tr></table></figure>

<h4 id="5-什么情况下使用OpenCV，什么情况下使用深度学习？"><a href="#5-什么情况下使用OpenCV，什么情况下使用深度学习？" class="headerlink" title="5.什么情况下使用OpenCV，什么情况下使用深度学习？"></a>5.什么情况下使用OpenCV，什么情况下使用深度学习？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Opencv：不需要程序理解图像的场景和内容，图像相对单一，干扰因素较少，需求比较简单，数据量比较少</span><br><span class="line">深度学习：需要程序理解图像的内容和场景，场景复杂，干扰因素多，样本变化大，需求复杂，数据量足够大</span><br></pre></td></tr></table></figure>

<h4 id="6-准确率是多少？"><a href="#6-准确率是多少？" class="headerlink" title="6.准确率是多少？"></a>6.准确率是多少？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">工业中至少要95%以上，越高越好，不要过拟合</span><br></pre></td></tr></table></figure>

<h4 id="7-写项目经验注意的问题"><a href="#7-写项目经验注意的问题" class="headerlink" title="7.写项目经验注意的问题"></a>7.写项目经验注意的问题</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">项目背景(需求)：用户是谁？用在什么地方？解决什么问题？</span><br><span class="line">数据集：来源？数量？数据增强？标注？预处理手段？</span><br><span class="line">模型：模型选择？训练过程？调参优化过程？</span><br><span class="line">遇到了什么问题？怎么解决的？</span><br><span class="line">过拟合，欠拟合问题怎么解决的？</span><br><span class="line">效果？</span><br><span class="line">部署？</span><br></pre></td></tr></table></figure>

<h4 id="8-什么是有监督学习（Supervised-Learning）和无监督学习（Unsupervised-Learning）？请举例说明每种类型的应用场景"><a href="#8-什么是有监督学习（Supervised-Learning）和无监督学习（Unsupervised-Learning）？请举例说明每种类型的应用场景" class="headerlink" title="8.什么是有监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）？请举例说明每种类型的应用场景"></a>8.什么是有监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）？请举例说明每种类型的应用场景</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">有监督：训练数据集包含了标签，在训练过程中，模型学习输入与标签之间的映射关系</span><br><span class="line">分类：图像分类、垃圾邮件分类</span><br><span class="line">回归：房价预测</span><br><span class="line"></span><br><span class="line">无监督：不依赖于标注数据，模型通过输入数据自行发现数据的结构或模式</span><br><span class="line">聚类：客户分组</span><br><span class="line">降维：从高维度数据中提取主要特征</span><br></pre></td></tr></table></figure>

<h4 id="9-贝叶斯公式及推导过程，有哪些应用场景？"><a href="#9-贝叶斯公式及推导过程，有哪些应用场景？" class="headerlink" title="9.贝叶斯公式及推导过程，有哪些应用场景？"></a>9.贝叶斯公式及推导过程，有哪些应用场景？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">公式：P(A|B) &#x3D; P(B|A)⋅P(A) &#x2F; P(B)</span><br><span class="line">解释：由先验概率和条件概率，推算出后验概率</span><br><span class="line"></span><br><span class="line">推导：</span><br><span class="line">由联合概率可知：P(A∩B)&#x3D;P(A∣B)⋅P(B)</span><br><span class="line">由联合概率对称性可知：P(A∩B)&#x3D;P(B∣A)⋅P(A)</span><br><span class="line">等式相等：P(A∣B)⋅P(B) &#x3D; P(B∣A)⋅P(A)</span><br><span class="line">两边除以P(B)得：P(A∣B) &#x3D; P(B∣A)⋅P(A) &#x2F; P(B)</span><br><span class="line"></span><br><span class="line">应用：</span><br><span class="line">朴素贝叶斯分类器</span><br><span class="line">医疗诊断中，计算患者患有特定疾病的概率</span><br><span class="line">风险评估</span><br></pre></td></tr></table></figure>

<h4 id="10-什么是似然？"><a href="#10-什么是似然？" class="headerlink" title="10.什么是似然？"></a>10.什么是似然？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">概念：在已知某些数据的情况下，模型参数取特定值的概率</span><br><span class="line">与概率的区别：概率描述的是在已知参数的情况下，观测到某数据的概率，而似然则是相反的情况，即在已知数据的情况下，参数的可能值</span><br></pre></td></tr></table></figure>

<h4 id="11-什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？"><a href="#11-什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？" class="headerlink" title="11.什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？"></a>11.什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">欠拟合：指模型无法从训练数据中学习到足够的模式，导致其在训练集和测试集上都表现不佳</span><br><span class="line">原因：模型太小太简单、训练数据太少、训练时间不够</span><br><span class="line">解决：</span><br><span class="line">    1.增加模型复杂度</span><br><span class="line">    2.增加特征数量</span><br><span class="line">    3.增加训练数据</span><br><span class="line">    4.训练更多轮数</span><br><span class="line">    5.减小正则化强度</span><br><span class="line"></span><br><span class="line">过拟合：指模型在训练集上表现很好，但在测试集上表现较差，即模型过度适应了训练数据，忽略了数据的总体趋势，导致泛化能力差</span><br><span class="line">原因：模型太复杂、数据集太小、训练时间过长</span><br><span class="line">解决：</span><br><span class="line">    1.数据增强</span><br><span class="line">    2.正则化</span><br><span class="line">    3.提前终止</span><br><span class="line">    4.集成学习</span><br><span class="line">    5.dropout</span><br></pre></td></tr></table></figure>

<h4 id="12-神经网络加速训练方法有哪些？"><a href="#12-神经网络加速训练方法有哪些？" class="headerlink" title="12.神经网络加速训练方法有哪些？"></a>12.神经网络加速训练方法有哪些？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">硬件：多GPU、分布式训练</span><br><span class="line">数据：归一化、数据增强</span><br><span class="line">模型：更好的优化器、BN、量化、剪枝、使用预训练模型</span><br><span class="line">训练：提前终止、混合精度训练、自动化超参数调整</span><br></pre></td></tr></table></figure>

<h4 id="13-目标检测常用算法有哪些，简述对算法的理解"><a href="#13-目标检测常用算法有哪些，简述对算法的理解" class="headerlink" title="13.目标检测常用算法有哪些，简述对算法的理解"></a>13.目标检测常用算法有哪些，简述对算法的理解</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">两阶段检测</span><br><span class="line">   	先产生候选区，在候选区上分类+定位</span><br><span class="line">   	速度相对比较慢，精度高</span><br><span class="line">   	RCNN系列  </span><br><span class="line">   	</span><br><span class="line">一阶段检测</span><br><span class="line">   	预定义候选区，直接在特征图上分类+定位</span><br><span class="line">   	速度比较快，精度较低</span><br><span class="line">   	YOLO系列、SSD、RetinaNet</span><br></pre></td></tr></table></figure>

<h4 id="14-什么是感受野？"><a href="#14-什么是感受野？" class="headerlink" title="14.什么是感受野？"></a>14.什么是感受野？</h4><h4 id="15-L1、L2、smooth-L1正则化的区别"><a href="#15-L1、L2、smooth-L1正则化的区别" class="headerlink" title="15.L1、L2、smooth L1正则化的区别"></a>15.L1、L2、smooth L1正则化的区别</h4><h4 id="16-YOLOv8中的objectness-loss是什么？"><a href="#16-YOLOv8中的objectness-loss是什么？" class="headerlink" title="16.YOLOv8中的objectness loss是什么？"></a>16.YOLOv8中的objectness loss是什么？</h4><h4 id="17-什么是特征归一化？为什么要归一化？"><a href="#17-什么是特征归一化？为什么要归一化？" class="headerlink" title="17.什么是特征归一化？为什么要归一化？"></a>17.什么是特征归一化？为什么要归一化？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">归一化一般是将数据映射到指定的范围（[0, 1] 或 [-1, 1]），从而消除不同特征量纲的影响。</span><br><span class="line">进行归一化处理，使得不同指标之间处于同一数量级，具有可比性。另外还能加速模型收敛，提升性能</span><br></pre></td></tr></table></figure>

<h4 id="18-归一化常用方法？"><a href="#18-归一化常用方法？" class="headerlink" title="18.归一化常用方法？"></a>18.归一化常用方法？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Min-Max Normalization</span><br><span class="line">公式：X &#x3D; (X-Xmin) &#x2F; (Xmax - Xmin)</span><br><span class="line">--------------------------------------</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import sklearn.preprocessing as sp</span><br><span class="line"></span><br><span class="line">raw_sample &#x3D; np.array([[3.0, -100.0, 2000.0],</span><br><span class="line">                       [0.0, 400.0, 3000.0],</span><br><span class="line">                       [1.0, -400.0, 2000.0]])</span><br><span class="line"></span><br><span class="line">mms_sample &#x3D; raw_sample.copy()</span><br><span class="line"></span><br><span class="line"># 1.减去最小值</span><br><span class="line"># 2.减完之后的结果&#x2F;极差</span><br><span class="line">for col in mms_sample.T:</span><br><span class="line">    col_min &#x3D; col.min()</span><br><span class="line">    col_max &#x3D; col.max()</span><br><span class="line">    col -&#x3D; col_min</span><br><span class="line">    col &#x2F;&#x3D; (col_max - col_min)</span><br><span class="line">  </span><br><span class="line">    </span><br><span class="line"># 基于skLearn提供的API实现</span><br><span class="line">scaler &#x3D; sp.MinMaxScaler()</span><br><span class="line">res &#x3D; scaler.fit_transform(raw_sample)</span><br></pre></td></tr></table></figure>

<h4 id="19-归一化处理适用模型"><a href="#19-归一化处理适用模型" class="headerlink" title="19.归一化处理适用模型"></a>19.归一化处理适用模型</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">应用归一化的模型：在实际应用中，通过梯度下降法求解的模型通常是需要归一化的，包括线性回归、逻辑回归、支持向量机、神经网络等模型。</span><br><span class="line">不使用归一化的模型：如决策树分类</span><br></pre></td></tr></table></figure>

<h4 id="20-什么是标准化？常用方法？"><a href="#20-什么是标准化？常用方法？" class="headerlink" title="20.什么是标准化？常用方法？"></a>20.什么是标准化？常用方法？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">标准化是将特征值调整为均值为0，标准差为1的标准正态分布</span><br><span class="line"></span><br><span class="line">Z-Score Normalization</span><br><span class="line">公式：X &#x3D; (X - Xmean) &#x2F; Xstd</span><br><span class="line">-----------------------------------</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import sklearn.preprocessing as sp</span><br><span class="line"></span><br><span class="line">raw_sample &#x3D; np.array([[3.0, -100.0, 2000.0],</span><br><span class="line">                       [0.0, 400.0, 3000.0],</span><br><span class="line">                       [1.0, -400.0, 2000.0]])</span><br><span class="line"></span><br><span class="line">std_sample &#x3D; raw_sample.copy()</span><br><span class="line"></span><br><span class="line"># 1.减去当前列的平均值</span><br><span class="line"># 2.离差&#x2F;原始数据的标准差</span><br><span class="line">for col in std_sample.T:</span><br><span class="line">    col_mean &#x3D; col.mean()  # 平均值</span><br><span class="line">    col_std &#x3D; col.std()  # 标准差</span><br><span class="line">    col -&#x3D; col_mean</span><br><span class="line">    col &#x2F;&#x3D; col_std</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"># 基于skLearn提供的API实现</span><br><span class="line">scaler &#x3D; sp.StandardScaler()</span><br><span class="line">res &#x3D; scaler.fit_transform(raw_sample)</span><br></pre></td></tr></table></figure>

<h4 id="21-标准化和归一化的联系和区别"><a href="#21-标准化和归一化的联系和区别" class="headerlink" title="21.标准化和归一化的联系和区别"></a>21.标准化和归一化的联系和区别</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">联系:</span><br><span class="line">    我们都知道归一化是指normalization，标准化是指standardization，但根据wiki上对feature scaling方法的定义，standardization其实就是z-score normalization，也就是说标准化其实是归一化的一种，而一般情况下，我们会把z-score归一化称为标准化，把min-max归一化简称为归一化</span><br><span class="line">    目的：都是通过缩放和平移来实现数据映射，消除不同特征量纲的影响</span><br><span class="line"></span><br><span class="line">区别：</span><br><span class="line">    归一化不会改变数据的状态分布，但标准化会</span><br><span class="line">    归一化会将数据限定在一个具体的范围内，如 [0, 1]，但标准化不会</span><br><span class="line">    归一化只受原样本数据中的极值影响，而标准化则受所有样本值的影响</span><br><span class="line">    归一化对异常值敏感，而标准化则对异常值鲁棒</span><br></pre></td></tr></table></figure>

<h4 id="22-均值、离差、离差方、方差、标准差之间的关系"><a href="#22-均值、离差、离差方、方差、标准差之间的关系" class="headerlink" title="22.均值、离差、离差方、方差、标准差之间的关系"></a>22.均值、离差、离差方、方差、标准差之间的关系</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">S &#x3D; np.array([1, 2, 3, 4, 5, 6])</span><br><span class="line"></span><br><span class="line"># 均值</span><br><span class="line">mean &#x3D; np.mean(S)</span><br><span class="line">print(mean)  # 3.5</span><br><span class="line"></span><br><span class="line"># 离差 &#x3D; 观测值 - 均值</span><br><span class="line">deviation &#x3D; S - mean</span><br><span class="line">print(deviation)  # [-2.5 -1.5 -0.5  0.5  1.5  2.5]</span><br><span class="line"></span><br><span class="line"># 离差方 &#x3D; 离差 ** 2</span><br><span class="line">deviation_square &#x3D; deviation ** 2</span><br><span class="line">print(deviation_square)  # [6.25 2.25 0.25 0.25 2.25 6.25]</span><br><span class="line"></span><br><span class="line"># 方差 &#x3D; 离差方的均值</span><br><span class="line">variance &#x3D; np.mean(deviation_square)</span><br><span class="line">print(variance)  # 2.9166666666666665</span><br><span class="line"></span><br><span class="line"># 标准差 &#x3D; 方差的平方根</span><br><span class="line">std &#x3D; np.sqrt(variance)</span><br><span class="line">print(std)  # 1.707825127659933</span><br></pre></td></tr></table></figure>

<h4 id="23-方差和标准差有什么区别？"><a href="#23-方差和标准差有什么区别？" class="headerlink" title="23.方差和标准差有什么区别？"></a>23.方差和标准差有什么区别？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">方差和标准差都可以用来衡量数据的离散程度</span><br><span class="line">区别：</span><br><span class="line">1.计算方法不同</span><br><span class="line">2.单位不同：标准差单位与数据的单位一致，因此更直观易理解</span><br><span class="line"></span><br><span class="line">方差和标准差的缺点：</span><br><span class="line">1.对异常值比较敏感</span><br><span class="line">2.只能衡量单个变量的离散程度，不能反映变量之间的关系</span><br><span class="line">3.数据需要满足正态分布</span><br></pre></td></tr></table></figure>

<h4 id="24-回归问题的模型评估指标"><a href="#24-回归问题的模型评估指标" class="headerlink" title="24.回归问题的模型评估指标"></a>24.回归问题的模型评估指标</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">1.均方误差(Mean Squared Error, MSE)</span><br><span class="line">  公式：MSE &#x3D; Σ(y_i - y&#39;_i)^2 &#x2F; n</span><br><span class="line">  取值：越小越好</span><br><span class="line">  特点：L2范数，对离群值敏感，因为平方放大了误差</span><br><span class="line"></span><br><span class="line">2.均方根误差（Root Mean Squared Error, RMSE）</span><br><span class="line">  公式：RMSE &#x3D; √MSE</span><br><span class="line">  取值：越小越好</span><br><span class="line">  特点：RMSE是MSE的平方根，其单位与原始数据相同，便于描述真实值。也对离群值敏感</span><br><span class="line">  </span><br><span class="line">3.平均绝对误差（Mean Absolute Error, MAE）</span><br><span class="line">  公式：MAE &#x3D; Σ|y_i - y&#39;_i| &#x2F; n</span><br><span class="line">  取值：越小越好</span><br><span class="line">  特点：L1范数，对离群值不敏感</span><br><span class="line">  </span><br><span class="line">4.决定系数&#x2F;拟合优度（R² 或 Coefficient of Determination）</span><br><span class="line">  解释：表示模型中自变量能解释因变量变异的百分比</span><br><span class="line">  公式：R2 &#x3D; 1 - MSE &#x2F; Variance</span><br><span class="line">  取值：0～1之间，越大越好</span><br><span class="line">  特点：仅表示拟合程度，不代表模型预测准确度</span><br></pre></td></tr></table></figure>

<h4 id="25-分类问题中的TP、FP、TN、FN是什么"><a href="#25-分类问题中的TP、FP、TN、FN是什么" class="headerlink" title="25.分类问题中的TP、FP、TN、FN是什么"></a>25.分类问题中的TP、FP、TN、FN是什么</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">TP：True Positive，正确得预测为正样本，实际就是正样本，即正样本被正确识别的数量</span><br><span class="line">FP：False Positive，错误得预测为正样本，实际为负样本，即误报的数量</span><br><span class="line">TN：True Negative，正确得预测为负样本，实际就是负样本，即负样本被正确识别的数量</span><br><span class="line">FN：False Negative，错误得预测为负样本，实际为正样本，即漏报的数量</span><br><span class="line"></span><br><span class="line">TP+FN：真实正样本的数量</span><br><span class="line">FP+TN：真实负样本的数量</span><br><span class="line">TP+FP：预测为正样本的数量</span><br><span class="line">TN+FN: 预测为负样本的数量</span><br><span class="line">TP+TN: 预测正确的数量</span><br><span class="line">TP+TN+FP+FN: 样本总数量</span><br></pre></td></tr></table></figure>

<h4 id="26-如何查看混淆矩阵"><a href="#26-如何查看混淆矩阵" class="headerlink" title="26.如何查看混淆矩阵"></a>26.如何查看混淆矩阵</h4><table>
<thead>
<tr>
<th></th>
<th>Real A</th>
<th>Real B</th>
</tr>
</thead>
<tbody><tr>
<td>Predict A</td>
<td>10(TP)</td>
<td>20(FP)</td>
</tr>
<tr>
<td>Predict B</td>
<td>30(FN)</td>
<td>5(TN)</td>
</tr>
</tbody></table>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">该类的预测总数：某一行的和</span><br><span class="line">该类的真实总数：某一列的和</span><br><span class="line">预测对的数量：主对角线上的值</span><br><span class="line"></span><br><span class="line">以A为例：</span><br><span class="line">    TP: 预测为A，实际也为A &#x3D; 10</span><br><span class="line">    FP: 预测为A，实际不是A &#x3D; 20</span><br><span class="line">    TN: 预测为B，实际也为B &#x3D; 5</span><br><span class="line">    FN: 预测为B，实际为A &#x3D; 30 </span><br><span class="line">    Accuracy(和某个类别无关)：预测正确的数量 &#x2F; 样本总数量 &#x3D; 10 + 5 &#x2F; 10 + 20 + 30 + 5</span><br><span class="line">    Precision(A)：正确预测为A的数量 &#x2F; 预测为A的数量（行） &#x3D; 10 &#x2F; 10 + 20</span><br><span class="line">    Recall(A): 正确预测为A的数量 &#x2F; 真实为A的数量（列） &#x3D; 10 &#x2F; 10 + 30</span><br></pre></td></tr></table></figure>

<h4 id="27-分类问题的模型评估指标"><a href="#27-分类问题的模型评估指标" class="headerlink" title="27.分类问题的模型评估指标"></a>27.分类问题的模型评估指标</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">注意：每个类别都有自己的查准率、召回率、f1得分</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">假设有100张图片，50张狗（正样本），50张猫（负样本），模型预测结果为60张狗（其中有40张是正确的，还有20张是猫）、40张猫（10张狗 + 30张猫）</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">1.准确率（Accuracy）</span><br><span class="line">  公式：(TP+TN) &#x2F; (TP+TN+FP+FN)</span><br><span class="line">  解释：预测正确的数量 &#x2F; 样本总数量 &#x3D; (40 + 30) &#x2F; 100 &#x3D; 0.7</span><br><span class="line">  特点：如果样本不平衡，则准确率就没有参考价值</span><br><span class="line"></span><br><span class="line">2.查准率（Precision）</span><br><span class="line">  公式：TP &#x2F; (TP+FP) &#x3D; 40 &#x2F; 60 &#x3D; 0.67</span><br><span class="line">  解释：正确预测为正样本的数量 &#x2F; 预测为正样本的数量。Precision越高，表示FP越小，即误报越少</span><br><span class="line">  </span><br><span class="line">3.召回率&#x2F;查全率（Recall）</span><br><span class="line">  公式：TP &#x2F; (TP+FN) &#x3D; 40 &#x2F; 50 &#x3D; 0.8</span><br><span class="line">  解释：正确预测为正样本的数量 &#x2F; 真实正样本的数量。Recall越高，表示FN越小，即漏报越少</span><br><span class="line">  </span><br><span class="line">4.F1分数（F1 Score）</span><br><span class="line">  公式：F1 &#x3D; 2 * Precision * Recall &#x2F; (Precision + Recall)</span><br><span class="line">  解释：F1分数是查准率和召回率的调和平均数，在两者之间取得平衡。适用于需要在查准率和召回率之间权衡的场景。</span><br><span class="line"> </span><br><span class="line">5.混淆矩阵（Confusion Matrix）</span><br><span class="line"> </span><br><span class="line">6.ROC和AUC</span><br><span class="line">  ROC 曲线以FPR为横坐标，以TPR为纵坐标，连接不同阈值下的点绘制而成。</span><br><span class="line">    真正率（TPR）&#x3D; 灵敏度 &#x3D; Recall &#x3D; TP&#x2F;(TP+FN)</span><br><span class="line">    假正率（FPR） &#x3D; 1- 特异度 &#x3D; FP&#x2F;(FP+TN)，代表有多少负样本被错误得预测成了正样本</span><br><span class="line">  ROC 曲线越靠近左上角，说明模型性能越好</span><br><span class="line">  </span><br><span class="line">  AUC是 ROC 曲线下的面积，其值介于 0 和 1 之间，值越大，说明模型性能越好</span><br><span class="line">  </span><br><span class="line">  特点：可以避免样本不平衡的问题，因为TPR只关注正样本，FPR只关注负样本</span><br></pre></td></tr></table></figure>

<h4 id="28-回归问题的损失函数，为何使用平方（MSE）而不是绝对值（MAE）？"><a href="#28-回归问题的损失函数，为何使用平方（MSE）而不是绝对值（MAE）？" class="headerlink" title="28.回归问题的损失函数，为何使用平方（MSE）而不是绝对值（MAE）？"></a>28.回归问题的损失函数，为何使用平方（MSE）而不是绝对值（MAE）？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">因为MSE函数是可微的，而MAE函数不可微，具体的：</span><br><span class="line">1.曲线最低点可导</span><br><span class="line">2.越接近最低点，曲线的坡度逐渐放缓，有助于通过当前的梯度来判断接近最低点的程度</span><br></pre></td></tr></table></figure>
<p><img src="../images/ml_review_mse_loss.png" alt="mse_loss"></p>
<h4 id="29-损失函数和评估函数（指标）的区别？"><a href="#29-损失函数和评估函数（指标）的区别？" class="headerlink" title="29.损失函数和评估函数（指标）的区别？"></a>29.损失函数和评估函数（指标）的区别？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">损失函数作用于训练集，为梯度下降提供方向，用来训练模型参数</span><br><span class="line">评估函数（指标）作用于验证集和测试集，用于评估模型</span><br></pre></td></tr></table></figure>

<h4 id="30-什么是超参数？有哪些常用的超参数调优手段？"><a href="#30-什么是超参数？有哪些常用的超参数调优手段？" class="headerlink" title="30.什么是超参数？有哪些常用的超参数调优手段？"></a>30.什么是超参数？有哪些常用的超参数调优手段？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">超参数是在训练之前，人为预习设定的参数，而不是在训练中获得的参数</span><br><span class="line"></span><br><span class="line">调优手段：</span><br><span class="line">1.网格搜索（Grid Search）</span><br><span class="line">  定义：在预定义的超参数空间内进行穷举搜索，尝试所有可能的组合</span><br><span class="line">  特点：实现简单，但时间长，计算开销大</span><br><span class="line">  </span><br><span class="line">2.随机搜索（Random Search）</span><br><span class="line">  定义：从预定义的超参数空间内随机选择超参数组合进行评估</span><br><span class="line">  特点：相较网格搜索更高效，但可能无法找到最优组合</span><br><span class="line">  </span><br><span class="line">3.贝叶斯优化（Bayesian Optimization）</span><br><span class="line">  定义：一种基于贝叶斯定理的调优方法。它会根据已评估的超参数组合来预测新的超参数组合。</span><br><span class="line">  特点：比网格搜索和随机搜索更有效，但需要更多的计算时间 </span><br><span class="line">  </span><br><span class="line">4.遗传算法（Genetic Algorithms）</span><br><span class="line">  定义：使用自然选择等生物进化的思想来优化超参数</span><br></pre></td></tr></table></figure>

<h4 id="31-有哪些常见的超参数？各自对模型有怎样的影响？"><a href="#31-有哪些常见的超参数？各自对模型有怎样的影响？" class="headerlink" title="31.有哪些常见的超参数？各自对模型有怎样的影响？"></a>31.有哪些常见的超参数？各自对模型有怎样的影响？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">1.学习率（Learning Rate）</span><br><span class="line">  定义：学习率控制着模型参数更新的步长</span><br><span class="line">  影响：学习率太大导致无法收敛，太小导致收敛缓慢</span><br><span class="line">  </span><br><span class="line">2.批量大小（Batch Size）</span><br><span class="line">  定义：在一次迭代中使用的训练样本数量</span><br><span class="line">  影响：较大的batch size可以提高训练速度，但会占用更大的内存和计算资源，较小的则可能导致收敛不稳定</span><br><span class="line">  </span><br><span class="line">3.正则化参数（Regularization Parameter）</span><br><span class="line">  定义：用于控制模型的复杂度，以避免过拟合</span><br><span class="line">  影响：太大可能欠拟合，太小可能过拟合</span><br><span class="line">  </span><br><span class="line">4.隐藏层数量和神经元数量（Number of Hidden Layers and Neurons）</span><br><span class="line">  定义：决定了神经网络的容量和表达能力</span><br><span class="line">  影响：更多的隐藏层和神经元可以捕捉更复杂的模式，但也增加了模型复杂度和过拟合的风险</span><br><span class="line">  </span><br><span class="line">5.迭代次数（Epochs）</span><br><span class="line">  定义：模型训练的轮数</span><br><span class="line">  影响：过少可能导致模型没有学习到数据的特征，过多可能导致过拟合</span><br><span class="line">  </span><br><span class="line">6.优化器（Optimizer）</span><br><span class="line">  定义：优化器决定了模型的权重更新策略</span><br><span class="line">  影响：不同优化器有不同的收敛速度和稳定性，对模型的最终性能影响显著</span><br><span class="line">  </span><br><span class="line">7.权重初始化（Weight Initialization）</span><br><span class="line">  定义：权重初始化影响模型的初始状态，从而影响训练收敛速度和结果</span><br><span class="line">  影响：常见的方法有随机初始化、Xavier初始化和He初始化等。选择合适的初始化方法可以加快收敛速度，避免梯度消失或梯度爆炸</span><br></pre></td></tr></table></figure>

<h4 id="32-什么是置信概率？"><a href="#32-什么是置信概率？" class="headerlink" title="32. 什么是置信概率？"></a>32. 什么是置信概率？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">置信概率指模型对某个预测结果的确信程度，通常，分类模型（如逻辑回归、神经网络、随机森林等）在进行预测时，不仅给出一个类别标签，还会输出每个类别的置信概率。</span><br><span class="line">值越大说明越确定</span><br></pre></td></tr></table></figure>

<h4 id="33-什么是交叉验证？它有哪些常见类型？"><a href="#33-什么是交叉验证？它有哪些常见类型？" class="headerlink" title="33.什么是交叉验证？它有哪些常见类型？"></a>33.什么是交叉验证？它有哪些常见类型？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">交叉验证（Cross-Validation）是一种评估模型性能的技术，在样本数量较少的情况下，它将数据集分成多份，每份轮流作为测试集，剩下部分作为训练集，通过这种方式，可以多次评估模型，每次的评估结果综合起来给出模型的总体性能</span><br><span class="line"></span><br><span class="line">常见类型：</span><br><span class="line">1.K折交叉验证（K-Fold CV）</span><br><span class="line">  定义: 将数据集随机分成k个子集（或称为“折”），然后进行k次训练和测试。每次用k-1个子集进行训练，用剩下的一个子集进行测试</span><br><span class="line">  </span><br><span class="line">2.留一法交叉验证（Leave-One-Out Cross-Validation, LOOCV）</span><br><span class="line">  定义: 留一法交叉验证是一种特殊的 K 折交叉验证，其中 k 等于样本数。在留一法交叉验证中，每次只使用一个样本作为测试集，其余样本作为训练集</span><br><span class="line">  特点：最大限度利用数据，但计算量大</span><br></pre></td></tr></table></figure>

<h4 id="34-对于类别不均衡问题，有哪些处理方法？"><a href="#34-对于类别不均衡问题，有哪些处理方法？" class="headerlink" title="34.对于类别不均衡问题，有哪些处理方法？"></a>34.对于类别不均衡问题，有哪些处理方法？</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">数据层面：</span><br><span class="line">1.过采样（Oversampling）：增加少数类样本的数量</span><br><span class="line">2.欠采样（Undersampling）：减少多数类样本的数量</span><br><span class="line">3.合成数据（Synthetic Data Generation）：合成新的少数类样本</span><br><span class="line"></span><br><span class="line">算法层面：</span><br><span class="line">1.调整类权重（Class Weight Adjustment）：给少数类样本赋予更高的权重，以增加其对损失函数的影响</span><br><span class="line">2.集成方法（Ensemble Methods）：使用集成学习方法，如Bagging、Boosting来提高模型对少数类的识别能力</span><br><span class="line">3.调整评估指标：使用适合不平衡数据集的评估指标，如PR曲线、F1、ROC、AUC</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/ml/" rel="tag"><i class="fa fa-tag"></i> ml</a>
              <a href="/tags/dl/" rel="tag"><i class="fa fa-tag"></i> dl</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/python-review/" rel="prev" title="Python复习">
      <i class="fa fa-chevron-left"></i> Python复习
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-数据从哪里来？如何构建数据集？"><span class="nav-text">1.数据从哪里来？如何构建数据集？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-数据量多大？"><span class="nav-text">2.数据量多大？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-数据量不够如何处理？"><span class="nav-text">3.数据量不够如何处理？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-采用的模型是什么？为什么使用YOLOv8？"><span class="nav-text">4.采用的模型是什么？为什么使用YOLOv8？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-什么情况下使用OpenCV，什么情况下使用深度学习？"><span class="nav-text">5.什么情况下使用OpenCV，什么情况下使用深度学习？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-准确率是多少？"><span class="nav-text">6.准确率是多少？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-写项目经验注意的问题"><span class="nav-text">7.写项目经验注意的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-什么是有监督学习（Supervised-Learning）和无监督学习（Unsupervised-Learning）？请举例说明每种类型的应用场景"><span class="nav-text">8.什么是有监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）？请举例说明每种类型的应用场景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9-贝叶斯公式及推导过程，有哪些应用场景？"><span class="nav-text">9.贝叶斯公式及推导过程，有哪些应用场景？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10-什么是似然？"><span class="nav-text">10.什么是似然？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？"><span class="nav-text">11.什么是欠拟合、过拟合？如何避免过拟合？如何避免欠拟合？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-神经网络加速训练方法有哪些？"><span class="nav-text">12.神经网络加速训练方法有哪些？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-目标检测常用算法有哪些，简述对算法的理解"><span class="nav-text">13.目标检测常用算法有哪些，简述对算法的理解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-什么是感受野？"><span class="nav-text">14.什么是感受野？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-L1、L2、smooth-L1正则化的区别"><span class="nav-text">15.L1、L2、smooth L1正则化的区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#16-YOLOv8中的objectness-loss是什么？"><span class="nav-text">16.YOLOv8中的objectness loss是什么？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#17-什么是特征归一化？为什么要归一化？"><span class="nav-text">17.什么是特征归一化？为什么要归一化？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#18-归一化常用方法？"><span class="nav-text">18.归一化常用方法？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#19-归一化处理适用模型"><span class="nav-text">19.归一化处理适用模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#20-什么是标准化？常用方法？"><span class="nav-text">20.什么是标准化？常用方法？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#21-标准化和归一化的联系和区别"><span class="nav-text">21.标准化和归一化的联系和区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#22-均值、离差、离差方、方差、标准差之间的关系"><span class="nav-text">22.均值、离差、离差方、方差、标准差之间的关系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#23-方差和标准差有什么区别？"><span class="nav-text">23.方差和标准差有什么区别？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#24-回归问题的模型评估指标"><span class="nav-text">24.回归问题的模型评估指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#25-分类问题中的TP、FP、TN、FN是什么"><span class="nav-text">25.分类问题中的TP、FP、TN、FN是什么</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#26-如何查看混淆矩阵"><span class="nav-text">26.如何查看混淆矩阵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#27-分类问题的模型评估指标"><span class="nav-text">27.分类问题的模型评估指标</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#28-回归问题的损失函数，为何使用平方（MSE）而不是绝对值（MAE）？"><span class="nav-text">28.回归问题的损失函数，为何使用平方（MSE）而不是绝对值（MAE）？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#29-损失函数和评估函数（指标）的区别？"><span class="nav-text">29.损失函数和评估函数（指标）的区别？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#30-什么是超参数？有哪些常用的超参数调优手段？"><span class="nav-text">30.什么是超参数？有哪些常用的超参数调优手段？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#31-有哪些常见的超参数？各自对模型有怎样的影响？"><span class="nav-text">31.有哪些常见的超参数？各自对模型有怎样的影响？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#32-什么是置信概率？"><span class="nav-text">32. 什么是置信概率？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#33-什么是交叉验证？它有哪些常见类型？"><span class="nav-text">33.什么是交叉验证？它有哪些常见类型？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#34-对于类别不均衡问题，有哪些处理方法？"><span class="nav-text">34.对于类别不均衡问题，有哪些处理方法？</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="roubin"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">roubin</p>
  <div class="site-description" itemprop="description">芝兰其室，金石其心<br/>仁义为友，道德为师</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">137</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">38</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">76</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/satorioh" title="GitHub → https://github.com/satorioh" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wangbinxp@gmail.com" title="E-Mail → mailto:wangbinxp@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2015 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">roubin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://roubinme.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://roubin.me/ml-review/";
    this.page.identifier = "ml-review/";
    this.page.title = "ML/DL复习";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://roubinme.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>

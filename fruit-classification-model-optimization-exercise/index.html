<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"roubin.me","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="记录一次较为满意的实验。调优过程参考了Chollet大神的《Python深度学习》第8章中部分内容 一、任务描述任务：水果图片分类，是一个典型的图像多分类任务 实验环境：colab (tensorflow 2.15.0) 数据集：爬虫从百度图片搜索结果爬取的，包含1036张水果图片，共5个类别（苹果288张、香蕉275张、葡萄216张、橙子276张、梨251张），分类较为均衡">
<meta property="og:type" content="article">
<meta property="og:title" content="基于CNN的水果分类与模型调优实验">
<meta property="og:url" content="https://roubin.me/fruit-classification-model-optimization-exercise/index.html">
<meta property="og:site_name" content="肉饼博客">
<meta property="og:description" content="记录一次较为满意的实验。调优过程参考了Chollet大神的《Python深度学习》第8章中部分内容 一、任务描述任务：水果图片分类，是一个典型的图像多分类任务 实验环境：colab (tensorflow 2.15.0) 数据集：爬虫从百度图片搜索结果爬取的，包含1036张水果图片，共5个类别（苹果288张、香蕉275张、葡萄216张、橙子276张、梨251张），分类较为均衡">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://roubin.me/images/folder.png">
<meta property="og:image" content="https://roubin.me/images/model_net.png">
<meta property="og:image" content="https://roubin.me/images/fruit_history_1.png">
<meta property="og:image" content="https://roubin.me/images/fruit_history_2.png">
<meta property="og:image" content="https://roubin.me/images/fruit_pretrain_net.png">
<meta property="og:image" content="https://roubin.me/images/vgg16_input.png">
<meta property="og:image" content="https://roubin.me/images/fruit_history_3.png">
<meta property="article:published_time" content="2024-03-06T03:28:19.000Z">
<meta property="article:modified_time" content="2024-03-13T06:43:21.856Z">
<meta property="article:author" content="roubin">
<meta property="article:tag" content="CNN">
<meta property="article:tag" content="模型调优">
<meta property="article:tag" content="keras">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://roubin.me/images/folder.png">

<link rel="canonical" href="https://roubin.me/fruit-classification-model-optimization-exercise/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>基于CNN的水果分类与模型调优实验 | 肉饼博客</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b55ece62ebeb2e72a8efe3f8b5b43960";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">肉饼博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Talk is cheap. Show me the code.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://roubin.me/fruit-classification-model-optimization-exercise/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="roubin">
      <meta itemprop="description" content="芝兰其室，金石其心<br/>仁义为友，道德为师">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="肉饼博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          基于CNN的水果分类与模型调优实验
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-06 11:28:19" itemprop="dateCreated datePublished" datetime="2024-03-06T11:28:19+08:00">2024-03-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-03-13 14:43:21" itemprop="dateModified" datetime="2024-03-13T14:43:21+08:00">2024-03-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DL/" itemprop="url" rel="index"><span itemprop="name">DL</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus：</span>
    
    <a title="disqus" href="/fruit-classification-model-optimization-exercise/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="fruit-classification-model-optimization-exercise/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>26k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>24 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>记录一次较为满意的实验。调优过程参考了Chollet大神的《Python深度学习》第8章中部分内容</p>
<h3 id="一、任务描述"><a href="#一、任务描述" class="headerlink" title="一、任务描述"></a>一、任务描述</h3><p>任务：水果图片分类，是一个典型的图像多分类任务</p>
<p>实验环境：colab (tensorflow 2.15.0)</p>
<p>数据集：爬虫从百度图片搜索结果爬取的，包含1036张水果图片，共5个类别（苹果288张、香蕉275张、葡萄216张、橙子276张、梨251张），分类较为均衡</p>
<a id="more"></a>
<p>数据文件夹结构，如下图：<br><img src="../images/folder.png" alt="folder.png"></p>
<h3 id="二、实验过程"><a href="#二、实验过程" class="headerlink" title="二、实验过程"></a>二、实验过程</h3><h4 id="1-数据准备"><a href="#1-数据准备" class="headerlink" title="1.数据准备"></a>1.数据准备</h4><h5 id="（1）将图片转为dataset"><a href="#（1）将图片转为dataset" class="headerlink" title="（1）将图片转为dataset"></a>（1）将图片转为dataset</h5><p>使用keras的<code>image_dataset_from_directory</code>接口，可以自动将fruits下的每个子文件夹当作一个class（分类），从而生成dataset(生成的label是文件夹名)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> image_dataset_from_directory</span><br><span class="line"></span><br><span class="line">base_dir = <span class="string">'fruits'</span></span><br><span class="line">train_ds, validation_ds = image_dataset_from_directory(base_dir, label_mode=<span class="string">'categorical'</span>,validation_split=<span class="number">0.2</span>,subset=<span class="string">"both"</span>,batch_size=<span class="number">32</span>,image_size=(<span class="number">180</span>, <span class="number">180</span>),seed=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>
<p>上述代码对dataset做了如下操作：</p>
<ul>
<li>validation_split=0.2：划分为训练集（80%）、验证集（20%），</li>
<li>image_size=(180, 180)：统一图片尺寸为180x180，减小后续训练时的计算量和内存占用</li>
<li>label_mode=’categorical’：label使用何种编码方式。此处为one-hot编码，对应后面使用的损失函数为categorical_crossentropy；如果label_mode设为’int’，则损失函数需要使用sparse_categorical_crossentropy</li>
</ul>
<h5 id="（2）划分测试集"><a href="#（2）划分测试集" class="headerlink" title="（2）划分测试集"></a>（2）划分测试集</h5><p>训练集用于模型训练中的参数调整，验证集用于模型超参数确定，测试集则用于最后的模型评估，虽然这里使用的数据集不大，但我还是划分了一个测试集出来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算validation_ds的大小</span></span><br><span class="line">num_validation_samples = tf.data.experimental.cardinality(validation_ds).numpy() <span class="comment"># 9</span></span><br><span class="line"><span class="comment"># 定义我们想要用于验证的样本数量，剩下的将用于测试</span></span><br><span class="line">num_val_samples = int(num_validation_samples * <span class="number">0.5</span>) <span class="comment"># 4</span></span><br><span class="line"><span class="comment"># 验证集</span></span><br><span class="line">val_ds = validation_ds.take(num_val_samples)</span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">test_ds = validation_ds.skip(num_val_samples)</span><br></pre></td></tr></table></figure>

<h4 id="2-模型构建与训练"><a href="#2-模型构建与训练" class="headerlink" title="2.模型构建与训练"></a>2.模型构建与训练</h4><h5 id="（1）构建"><a href="#（1）构建" class="headerlink" title="（1）构建"></a>（1）构建</h5><p><img src="../images/model_net.png" alt="img.png"><br>网络结构如上图，包含3个卷积池化组（用于图像特征提取、降维），并添加了Dropout层（正则化，防止过拟合，因为模型层数多，但相对的数据集并不大），然后是2个全连接层（对特征进行抽象整合，最后输出），构建代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">180</span>, <span class="number">180</span>, <span class="number">3</span>))</span><br><span class="line">x = layers.Rescaling(<span class="number">1.</span>/<span class="number">255</span>)(inputs) <span class="comment"># 归一化</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">32</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">"relu"</span>)(x) <span class="comment"># 使用3x3的卷积核</span></span><br><span class="line">x = layers.MaxPooling2D(pool_size=<span class="number">2</span>)(x) <span class="comment"># 使用window size 2x2、步长2的池化</span></span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x) <span class="comment"># 50%的随机丢弃率</span></span><br><span class="line">x = layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(pool_size=<span class="number">2</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(pool_size=<span class="number">2</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = layers.Flatten()(x) <span class="comment"># 展平成一维</span></span><br><span class="line">x = layers.Dense(<span class="number">512</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">5</span>, activation=<span class="string">"softmax"</span>)(x) <span class="comment"># 因为有5种类别，所以只需要5个神经元做输出</span></span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure>
<p>上述代码在开头还添加了一个Rescaling层，用于归一化（将数据映射到0～1之间，加速模型收敛，提高精度）</p>
<h5 id="（2）编译"><a href="#（2）编译" class="headerlink" title="（2）编译"></a>（2）编译</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(loss=<span class="string">"categorical_crossentropy"</span>,</span><br><span class="line">              optimizer=<span class="string">"rmsprop"</span>,</span><br><span class="line">              metrics=[<span class="string">"accuracy"</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>loss=”categorical_crossentropy”: 分类交叉熵损失函数</li>
<li>optimizer=”rmsprop”：优化器使用rmsprop（均方根前向梯度下降），一种梯度下降算法的改进版本，可动态调整学习率，提高训练效率</li>
<li>metrics=[“accuracy”]：使用精度（这里是CategoricalAccuracy）作为评估指标</li>
</ul>
<h5 id="（3）训练"><a href="#（3）训练" class="headerlink" title="（3）训练"></a>（3）训练</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    epochs=<span class="number">30</span>,</span><br><span class="line">    validation_data=val_ds)</span><br></pre></td></tr></table></figure>
<p>跑30轮，输出结果如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/30</span><br><span class="line">33/33 [==============================] - 9s 93ms/step - loss: 4.8970 - accuracy: 0.2325 - val_loss: 1.5861 - val_accuracy: 0.1641</span><br><span class="line">Epoch 2/30</span><br><span class="line">33/33 [==============================] - 2s 66ms/step - loss: 1.3967 - accuracy: 0.3933 - val_loss: 1.2182 - val_accuracy: 0.5078</span><br><span class="line">Epoch 3/30</span><br><span class="line">33/33 [==============================] - 2s 65ms/step - loss: 0.9339 - accuracy: 0.6651 - val_loss: 1.0185 - val_accuracy: 0.6250</span><br><span class="line">Epoch 4/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.7777 - accuracy: 0.7043 - val_loss: 0.8928 - val_accuracy: 0.7422</span><br><span class="line">Epoch 5/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.6181 - accuracy: 0.7646 - val_loss: 0.7527 - val_accuracy: 0.7422</span><br><span class="line">Epoch 6/30</span><br><span class="line">33/33 [==============================] - 2s 58ms/step - loss: 0.6319 - accuracy: 0.7876 - val_loss: 0.8239 - val_accuracy: 0.6875</span><br><span class="line">Epoch 7/30</span><br><span class="line">33/33 [==============================] - 2s 58ms/step - loss: 0.4638 - accuracy: 0.8373 - val_loss: 0.5568 - val_accuracy: 0.8359</span><br><span class="line">Epoch 8/30</span><br><span class="line">33/33 [==============================] - 3s 68ms/step - loss: 0.4330 - accuracy: 0.8526 - val_loss: 0.4941 - val_accuracy: 0.8203</span><br><span class="line">Epoch 9/30</span><br><span class="line">33/33 [==============================] - 2s 62ms/step - loss: 0.4230 - accuracy: 0.8632 - val_loss: 0.4629 - val_accuracy: 0.8750</span><br><span class="line">Epoch 10/30</span><br><span class="line">33/33 [==============================] - 2s 58ms/step - loss: 0.2967 - accuracy: 0.9100 - val_loss: 0.8572 - val_accuracy: 0.6719</span><br><span class="line">Epoch 11/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.3056 - accuracy: 0.9024 - val_loss: 0.3813 - val_accuracy: 0.8828</span><br><span class="line">Epoch 12/30</span><br><span class="line">33/33 [==============================] - 2s 58ms/step - loss: 0.2053 - accuracy: 0.9254 - val_loss: 0.4152 - val_accuracy: 0.8516</span><br><span class="line">Epoch 13/30</span><br><span class="line">33/33 [==============================] - 2s 68ms/step - loss: 0.2324 - accuracy: 0.9263 - val_loss: 0.3878 - val_accuracy: 0.8750</span><br><span class="line">Epoch 14/30</span><br><span class="line">33/33 [==============================] - 2s 66ms/step - loss: 0.2329 - accuracy: 0.9301 - val_loss: 0.3411 - val_accuracy: 0.9219</span><br><span class="line">Epoch 15/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.1377 - accuracy: 0.9665 - val_loss: 0.3957 - val_accuracy: 0.8906</span><br><span class="line">Epoch 16/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.1833 - accuracy: 0.9455 - val_loss: 0.2581 - val_accuracy: 0.9609</span><br><span class="line">Epoch 17/30</span><br><span class="line">33/33 [==============================] - 2s 58ms/step - loss: 0.0786 - accuracy: 0.9703 - val_loss: 0.3576 - val_accuracy: 0.8672</span><br><span class="line">Epoch 18/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.1816 - accuracy: 0.9598 - val_loss: 0.2799 - val_accuracy: 0.9531</span><br><span class="line">Epoch 19/30</span><br><span class="line">33/33 [==============================] - 2s 70ms/step - loss: 0.0762 - accuracy: 0.9789 - val_loss: 0.2764 - val_accuracy: 0.9453</span><br><span class="line">Epoch 20/30</span><br><span class="line">33/33 [==============================] - 2s 63ms/step - loss: 0.0911 - accuracy: 0.9761 - val_loss: 0.3179 - val_accuracy: 0.9531</span><br><span class="line">Epoch 21/30</span><br><span class="line">33/33 [==============================] - 2s 60ms/step - loss: 0.0966 - accuracy: 0.9818 - val_loss: 0.3839 - val_accuracy: 0.9609</span><br><span class="line">Epoch 22/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.0784 - accuracy: 0.9828 - val_loss: 0.2903 - val_accuracy: 0.9531</span><br><span class="line">Epoch 23/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.0491 - accuracy: 0.9856 - val_loss: 0.3415 - val_accuracy: 0.9453</span><br><span class="line">Epoch 24/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.3351 - val_accuracy: 0.9531</span><br><span class="line">Epoch 25/30</span><br><span class="line">33/33 [==============================] - 2s 70ms/step - loss: 0.0901 - accuracy: 0.9799 - val_loss: 0.3475 - val_accuracy: 0.9531</span><br><span class="line">Epoch 26/30</span><br><span class="line">33/33 [==============================] - 2s 63ms/step - loss: 0.0694 - accuracy: 0.9809 - val_loss: 0.2907 - val_accuracy: 0.9531</span><br><span class="line">Epoch 27/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.9531</span><br><span class="line">Epoch 28/30</span><br><span class="line">33/33 [==============================] - 2s 59ms/step - loss: 0.1168 - accuracy: 0.9780 - val_loss: 0.3631 - val_accuracy: 0.9531</span><br><span class="line">Epoch 29/30</span><br><span class="line">33/33 [==============================] - 2s 60ms/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.8567 - val_accuracy: 0.8672</span><br><span class="line">Epoch 30/30</span><br><span class="line">33/33 [==============================] - 2s 60ms/step - loss: 0.0501 - accuracy: 0.9885 - val_loss: 0.3891 - val_accuracy: 0.9531</span><br></pre></td></tr></table></figure>
<h4 id="3-评估与预测"><a href="#3-评估与预测" class="headerlink" title="3.评估与预测"></a>3.评估与预测</h4><h5 id="（1）绘制loss和accuracy曲线"><a href="#（1）绘制loss和accuracy曲线" class="headerlink" title="（1）绘制loss和accuracy曲线"></a>（1）绘制loss和accuracy曲线</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_history</span><span class="params">(history)</span>:</span></span><br><span class="line">    loss = history.history[<span class="string">'loss'</span>]</span><br><span class="line">    val_loss = history.history[<span class="string">'val_loss'</span>]</span><br><span class="line">    epochs = range(<span class="number">1</span>, len(loss) + <span class="number">1</span>)</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, loss, <span class="string">'bo'</span>, label=<span class="string">'Training loss'</span>)</span><br><span class="line">    plt.plot(epochs, val_loss, <span class="string">'b'</span>, label=<span class="string">'Validation loss'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation loss'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Loss'</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    acc = history.history[<span class="string">'accuracy'</span>]</span><br><span class="line">    val_acc = history.history[<span class="string">'val_accuracy'</span>]</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(epochs, acc, <span class="string">'bo'</span>, label=<span class="string">'Training acc'</span>)</span><br><span class="line">    plt.plot(epochs, val_acc, <span class="string">'b'</span>, label=<span class="string">'Validation acc'</span>)</span><br><span class="line">    plt.title(<span class="string">'Training and validation accuracy'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Accuracy'</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">    </span><br><span class="line">show_history(history)</span><br></pre></td></tr></table></figure>
<p><img src="../images/fruit_history_1.png" alt="loss和accuracy曲线"><br>如上图，loss和accuracy都不错，也没有太大的过拟合，说明Dropout还是很有效的</p>
<p>执行一下评估：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(test_ds)</span><br><span class="line">print(<span class="string">f"Test accuracy: <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<p>结果：0.925</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5/5 [==============================] - 1s 104ms/step - loss: 0.3252 - accuracy: 0.9248</span><br><span class="line">Test accuracy: 0.925</span><br></pre></td></tr></table></figure>

<h5 id="（2）预测并获取分类报告"><a href="#（2）预测并获取分类报告" class="headerlink" title="（2）预测并获取分类报告"></a>（2）预测并获取分类报告</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取预测结果</span></span><br><span class="line">y_pred = model.predict(test_ds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取测试集的真实标签</span></span><br><span class="line">y_true = np.concatenate([y <span class="keyword">for</span> x, y <span class="keyword">in</span> test_ds], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">y_pred = np.argmax(y_pred, axis=<span class="number">1</span>)</span><br><span class="line">y_true = np.argmax(y_true, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>模型使用softmax输出的是一个二维的概率值（5个分类各自可能的概率大小），而classification_report需要传入一维的真实label和预测值，所以这里使用np.argmax将每个样本中概率最大的值，转为对应的整数索引</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">print(y_true)</span><br><span class="line"></span><br><span class="line">array([1, 0, 3, 2, 2, 3, 3, 3, 0, 1, 3, 3, 1, 2, 4, 3, 2, 2, 3, 2, 2, 0,</span><br><span class="line">       3, 1, 1, 4, 4, 3, 3, 0, 0, 3, 0, 3, 0, 1, 1, 1, 1, 2, 4, 4, 2, 4,</span><br><span class="line">       1, 0, 0, 4, 4, 1, 1, 0, 2, 0, 3, 4, 3, 1, 2, 1, 3, 1, 3, 0, 3, 0,</span><br><span class="line">       0, 2, 1, 2, 4, 2, 3, 3, 4, 0, 0, 2, 1, 4, 0, 3, 2, 2, 0, 0, 1, 2,</span><br><span class="line">       1, 0, 3, 0, 2, 4, 3, 4, 1, 4, 2, 3, 0, 3, 2, 1, 4, 1, 3, 2, 0, 0,</span><br><span class="line">       1, 4, 0, 3, 4, 1, 3, 1, 2, 0, 3, 4, 0, 1, 4, 1, 0, 3, 4, 4, 4, 3,</span><br><span class="line">       4])</span><br></pre></td></tr></table></figure>
<p>最后看下分类报告的结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成分类报告</span></span><br><span class="line">report = classification_report(y_true, y_pred)</span><br><span class="line">print(report)</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       0.93      0.96      0.95        28</span><br><span class="line">           1       0.89      0.93      0.91        27</span><br><span class="line">           2       0.95      0.91      0.93        23</span><br><span class="line">           3       0.97      0.97      0.97        31</span><br><span class="line">           4       0.87      0.83      0.85        24</span><br><span class="line"></span><br><span class="line">    accuracy                           0.92       133</span><br><span class="line">   macro avg       0.92      0.92      0.92       133</span><br><span class="line">weighted avg       0.92      0.92      0.92       133</span><br></pre></td></tr></table></figure>
<p>从support一栏可以看到每个类别实际参与测试的样本数，总体还算均衡；accuracy是0.92，不错的成绩，但还有优化空间</p>
<h3 id="三、模型调优"><a href="#三、模型调优" class="headerlink" title="三、模型调优"></a>三、模型调优</h3><h4 id="1-数据增强（data-augmentation）"><a href="#1-数据增强（data-augmentation）" class="headerlink" title="1.数据增强（data augmentation）"></a>1.数据增强（data augmentation）</h4><p>图片的数据增强，指的是通过对原始图像进行变换、扩充等操作，增加训练数据的多样性，从而提高模型的泛化能力。对于数据集较小的情况，使用数据增强是一种很有效的解决方法</p>
<h5 id="（1）添加数据增强层"><a href="#（1）添加数据增强层" class="headerlink" title="（1）添加数据增强层"></a>（1）添加数据增强层</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data_augmentation = keras.Sequential(</span><br><span class="line">    [</span><br><span class="line">        layers.RandomFlip(<span class="string">"horizontal"</span>),</span><br><span class="line">        layers.RandomRotation(<span class="number">0.1</span>),</span><br><span class="line">        layers.RandomZoom(<span class="number">0.2</span>),</span><br><span class="line">    ]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>RandomFlip(“horizontal”):将水平翻转应用于随机抽取的50% 的图像</li>
<li>RandomRotation(0.1):将输入图像在[-10%,+10%]的范围随机旋转(这个范围是相对于整个圆的比例，用角度表示的话，范围是[-36，+36°])</li>
<li>RandomZoom(0.2):放大或缩小图像，缩放比例在[-20%，+20%]范围内随机取值</li>
</ul>
<h5 id="（2）重新构建模型"><a href="#（2）重新构建模型" class="headerlink" title="（2）重新构建模型"></a>（2）重新构建模型</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">inputs = keras.Input(shape=(<span class="number">180</span>, <span class="number">180</span>, <span class="number">3</span>))</span><br><span class="line">x = data_augmentation(inputs)</span><br><span class="line">x = layers.Rescaling(<span class="number">1.</span>/<span class="number">255</span>)(x)</span><br><span class="line">x = layers.Conv2D(filters=<span class="number">32</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(pool_size=<span class="number">2</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(pool_size=<span class="number">2</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = layers.Conv2D(filters=<span class="number">128</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.MaxPooling2D(pool_size=<span class="number">2</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">x = layers.Flatten()(x)</span><br><span class="line">x = layers.Dense(<span class="number">512</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">outputs = layers.Dense(<span class="number">5</span>, activation=<span class="string">"softmax"</span>)(x)</span><br><span class="line">model = keras.Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure>
<h5 id="（3）使用callback函数"><a href="#（3）使用callback函数" class="headerlink" title="（3）使用callback函数"></a>（3）使用callback函数</h5><p>keras的callback函数可以在训练过程的不同阶段执行特定的操作。它可以在训练的开始或结束、每个批次之前或之后等时刻执行诸如：中断训练、保存模型、加载一组不同的权重或改变模型的状态等</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">callbacks = [</span><br><span class="line">    keras.callbacks.ModelCheckpoint(</span><br><span class="line">        filepath=<span class="string">"fruits_with_aug.keras"</span>,</span><br><span class="line">        save_best_only=<span class="literal">True</span>,</span><br><span class="line">        monitor=<span class="string">"val_loss"</span>)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>这里设置为在训练过程中，监测val_loss，当其有更优值时，才覆盖保存之前的模型</p>
<h5 id="（4）训练与评估"><a href="#（4）训练与评估" class="headerlink" title="（4）训练与评估"></a>（4）训练与评估</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    epochs=<span class="number">50</span>,</span><br><span class="line">    validation_data=val_ds,</span><br><span class="line">    callbacks=callbacks)</span><br></pre></td></tr></table></figure>
<p>训练50轮（让其自动保存最优模型），结果如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/50</span><br><span class="line">33/33 [==============================] - 6s 99ms/step - loss: 5.9965 - accuracy: 0.2057 - val_loss: 1.6067 - val_accuracy: 0.2188</span><br><span class="line">Epoch 2/50</span><br><span class="line">33/33 [==============================] - 3s 95ms/step - loss: 1.5082 - accuracy: 0.3426 - val_loss: 1.4788 - val_accuracy: 0.3594</span><br><span class="line">Epoch 3/50</span><br><span class="line">33/33 [==============================] - 3s 94ms/step - loss: 1.3154 - accuracy: 0.4833 - val_loss: 1.2293 - val_accuracy: 0.5156</span><br><span class="line">Epoch 4/50</span><br><span class="line">33/33 [==============================] - 3s 76ms/step - loss: 0.9649 - accuracy: 0.6431 - val_loss: 1.3895 - val_accuracy: 0.3594</span><br><span class="line">Epoch 5/50</span><br><span class="line">33/33 [==============================] - 3s 94ms/step - loss: 0.8895 - accuracy: 0.6699 - val_loss: 1.1524 - val_accuracy: 0.5312</span><br><span class="line">Epoch 6/50</span><br><span class="line">33/33 [==============================] - 4s 102ms/step - loss: 0.7342 - accuracy: 0.7110 - val_loss: 0.9722 - val_accuracy: 0.5938</span><br><span class="line">Epoch 7/50</span><br><span class="line">33/33 [==============================] - 4s 103ms/step - loss: 0.6668 - accuracy: 0.7483 - val_loss: 0.7654 - val_accuracy: 0.7188</span><br><span class="line">Epoch 8/50</span><br><span class="line">33/33 [==============================] - 3s 91ms/step - loss: 0.6270 - accuracy: 0.7550 - val_loss: 0.7171 - val_accuracy: 0.7500</span><br><span class="line">Epoch 9/50</span><br><span class="line">33/33 [==============================] - 2s 63ms/step - loss: 0.7062 - accuracy: 0.7416 - val_loss: 0.7718 - val_accuracy: 0.7109</span><br><span class="line">Epoch 10/50</span><br><span class="line">33/33 [==============================] - 3s 93ms/step - loss: 0.5799 - accuracy: 0.7876 - val_loss: 0.6397 - val_accuracy: 0.7188</span><br><span class="line">Epoch 11/50</span><br><span class="line">33/33 [==============================] - 2s 63ms/step - loss: 0.6105 - accuracy: 0.7713 - val_loss: 0.7777 - val_accuracy: 0.7266</span><br><span class="line">Epoch 12/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.5552 - accuracy: 0.7943 - val_loss: 0.6451 - val_accuracy: 0.8359</span><br><span class="line">Epoch 13/50</span><br><span class="line">33/33 [==============================] - 2s 62ms/step - loss: 0.5336 - accuracy: 0.7962 - val_loss: 0.7344 - val_accuracy: 0.7266</span><br><span class="line">Epoch 14/50</span><br><span class="line">33/33 [==============================] - 3s 91ms/step - loss: 0.5414 - accuracy: 0.8019 - val_loss: 0.5638 - val_accuracy: 0.8047</span><br><span class="line">Epoch 15/50</span><br><span class="line">33/33 [==============================] - 4s 120ms/step - loss: 0.5912 - accuracy: 0.7952 - val_loss: 0.5456 - val_accuracy: 0.8359</span><br><span class="line">Epoch 16/50</span><br><span class="line">33/33 [==============================] - 2s 64ms/step - loss: 0.5123 - accuracy: 0.8038 - val_loss: 0.6544 - val_accuracy: 0.7812</span><br><span class="line">Epoch 17/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.5065 - accuracy: 0.8134 - val_loss: 0.6357 - val_accuracy: 0.8125</span><br><span class="line">Epoch 18/50</span><br><span class="line">33/33 [==============================] - 2s 62ms/step - loss: 0.5032 - accuracy: 0.8134 - val_loss: 0.6908 - val_accuracy: 0.6797</span><br><span class="line">Epoch 19/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.4910 - accuracy: 0.8230 - val_loss: 0.5172 - val_accuracy: 0.8516</span><br><span class="line">Epoch 20/50</span><br><span class="line">33/33 [==============================] - 4s 127ms/step - loss: 0.4639 - accuracy: 0.8182 - val_loss: 0.4979 - val_accuracy: 0.8203</span><br><span class="line">Epoch 21/50</span><br><span class="line">33/33 [==============================] - 3s 93ms/step - loss: 0.4460 - accuracy: 0.8383 - val_loss: 0.4966 - val_accuracy: 0.8359</span><br><span class="line">Epoch 22/50</span><br><span class="line">33/33 [==============================] - 4s 104ms/step - loss: 0.4515 - accuracy: 0.8325 - val_loss: 0.4871 - val_accuracy: 0.7891</span><br><span class="line">Epoch 23/50</span><br><span class="line">33/33 [==============================] - 3s 98ms/step - loss: 0.4238 - accuracy: 0.8297 - val_loss: 0.4816 - val_accuracy: 0.8125</span><br><span class="line">Epoch 24/50</span><br><span class="line">33/33 [==============================] - 3s 91ms/step - loss: 0.4302 - accuracy: 0.8469 - val_loss: 0.4627 - val_accuracy: 0.7969</span><br><span class="line">Epoch 25/50</span><br><span class="line">33/33 [==============================] - 3s 98ms/step - loss: 0.3918 - accuracy: 0.8660 - val_loss: 0.3938 - val_accuracy: 0.8906</span><br><span class="line">Epoch 26/50</span><br><span class="line">33/33 [==============================] - 4s 104ms/step - loss: 0.3881 - accuracy: 0.8545 - val_loss: 0.3335 - val_accuracy: 0.8828</span><br><span class="line">Epoch 27/50</span><br><span class="line">33/33 [==============================] - 2s 62ms/step - loss: 0.4168 - accuracy: 0.8622 - val_loss: 0.4780 - val_accuracy: 0.8203</span><br><span class="line">Epoch 28/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.3576 - accuracy: 0.8517 - val_loss: 0.3802 - val_accuracy: 0.8359</span><br><span class="line">Epoch 29/50</span><br><span class="line">33/33 [==============================] - 2s 62ms/step - loss: 0.3465 - accuracy: 0.8699 - val_loss: 0.3780 - val_accuracy: 0.8828</span><br><span class="line">Epoch 30/50</span><br><span class="line">33/33 [==============================] - 4s 101ms/step - loss: 0.3819 - accuracy: 0.8699 - val_loss: 0.3204 - val_accuracy: 0.8828</span><br><span class="line">Epoch 31/50</span><br><span class="line">33/33 [==============================] - 3s 72ms/step - loss: 0.3188 - accuracy: 0.8871 - val_loss: 0.4560 - val_accuracy: 0.7891</span><br><span class="line">Epoch 32/50</span><br><span class="line">33/33 [==============================] - 3s 89ms/step - loss: 0.3191 - accuracy: 0.8842 - val_loss: 0.3184 - val_accuracy: 0.8906</span><br><span class="line">Epoch 33/50</span><br><span class="line">33/33 [==============================] - 2s 60ms/step - loss: 0.3205 - accuracy: 0.8861 - val_loss: 0.6812 - val_accuracy: 0.7734</span><br><span class="line">Epoch 34/50</span><br><span class="line">33/33 [==============================] - 2s 64ms/step - loss: 0.2959 - accuracy: 0.8947 - val_loss: 0.6108 - val_accuracy: 0.7500</span><br><span class="line">Epoch 35/50</span><br><span class="line">33/33 [==============================] - 4s 98ms/step - loss: 0.2957 - accuracy: 0.9033 - val_loss: 0.3047 - val_accuracy: 0.8672</span><br><span class="line">Epoch 36/50</span><br><span class="line">33/33 [==============================] - 4s 119ms/step - loss: 0.3158 - accuracy: 0.8967 - val_loss: 0.2987 - val_accuracy: 0.8828</span><br><span class="line">Epoch 37/50</span><br><span class="line">33/33 [==============================] - 3s 91ms/step - loss: 0.3012 - accuracy: 0.8995 - val_loss: 0.2637 - val_accuracy: 0.8750</span><br><span class="line">Epoch 38/50</span><br><span class="line">33/33 [==============================] - 4s 102ms/step - loss: 0.2853 - accuracy: 0.8976 - val_loss: 0.2145 - val_accuracy: 0.9297</span><br><span class="line">Epoch 39/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.3012 - accuracy: 0.9062 - val_loss: 0.2886 - val_accuracy: 0.9141</span><br><span class="line">Epoch 40/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.3324 - accuracy: 0.8947 - val_loss: 0.2401 - val_accuracy: 0.9219</span><br><span class="line">Epoch 41/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.2516 - accuracy: 0.9110 - val_loss: 0.4127 - val_accuracy: 0.8594</span><br><span class="line">Epoch 42/50</span><br><span class="line">33/33 [==============================] - 3s 77ms/step - loss: 0.3404 - accuracy: 0.8995 - val_loss: 0.3658 - val_accuracy: 0.8516</span><br><span class="line">Epoch 43/50</span><br><span class="line">33/33 [==============================] - 2s 64ms/step - loss: 0.2272 - accuracy: 0.9148 - val_loss: 0.6187 - val_accuracy: 0.7891</span><br><span class="line">Epoch 44/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.2449 - accuracy: 0.9053 - val_loss: 0.2393 - val_accuracy: 0.9219</span><br><span class="line">Epoch 45/50</span><br><span class="line">33/33 [==============================] - 2s 62ms/step - loss: 0.2187 - accuracy: 0.9282 - val_loss: 0.5503 - val_accuracy: 0.7891</span><br><span class="line">Epoch 46/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.2731 - accuracy: 0.9072 - val_loss: 0.3276 - val_accuracy: 0.8750</span><br><span class="line">Epoch 47/50</span><br><span class="line">33/33 [==============================] - 2s 68ms/step - loss: 0.2309 - accuracy: 0.9177 - val_loss: 0.4530 - val_accuracy: 0.7969</span><br><span class="line">Epoch 48/50</span><br><span class="line">33/33 [==============================] - 3s 70ms/step - loss: 0.2479 - accuracy: 0.9234 - val_loss: 0.3031 - val_accuracy: 0.8672</span><br><span class="line">Epoch 49/50</span><br><span class="line">33/33 [==============================] - 2s 61ms/step - loss: 0.2583 - accuracy: 0.9187 - val_loss: 0.2214 - val_accuracy: 0.9453</span><br><span class="line">Epoch 50/50</span><br><span class="line">33/33 [==============================] - 3s 89ms/step - loss: 0.2406 - accuracy: 0.9225 - val_loss: 0.1947 - val_accuracy: 0.9531</span><br></pre></td></tr></table></figure>
<p>loss和accuracy曲线如下：<br><img src="../images/fruit_history_2.png" alt="loss和accuracy曲线"><br>依旧没有明显的过拟合，然后30轮和50轮的精度差别其实并不大</p>
<p>也来评估一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_model = keras.models.load_model(<span class="string">"fruits_with_aug.keras"</span>)</span><br><span class="line">test_loss, test_acc = test_model.evaluate(test_ds)</span><br><span class="line">print(<span class="string">f"Test accuracy: <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<p>结果：0.947，有小幅提升！</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5/5 [==============================] - 0s 21ms/step - loss: 0.1702 - accuracy: 0.9474</span><br><span class="line">Test accuracy: 0.947</span><br></pre></td></tr></table></figure>
<p>然后是分类报告（代码没变，我就不贴了）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       0.96      0.96      0.96        28</span><br><span class="line">           1       0.93      0.96      0.95        27</span><br><span class="line">           2       1.00      0.91      0.95        23</span><br><span class="line">           3       0.97      0.94      0.95        31</span><br><span class="line">           4       0.88      0.96      0.92        24</span><br><span class="line"></span><br><span class="line">    accuracy                           0.95       133</span><br><span class="line">   macro avg       0.95      0.95      0.95       133</span><br><span class="line">weighted avg       0.95      0.95      0.95       133</span><br></pre></td></tr></table></figure>
<p>accuracy 0.95,f1分数也基本都达到了0.95，说明数据增强还是有效果的</p>
<h4 id="2-使用预训练模型"><a href="#2-使用预训练模型" class="headerlink" title="2.使用预训练模型"></a>2.使用预训练模型</h4><p>好了，该上“牛刀”了——使用预训练模型。意思是在我们训练时，使用已经在其他数据集上训练好的模型作为起点，“站在巨人的肩膀上”</p>
<p>这里预训练模型选择了vgg16，它在ImageNet（该数据集包含超过1400万张属于1000个类别的图像）图像分类竞赛中取得了第二名，参数量大约为1.3亿</p>
<h5 id="（1）原理"><a href="#（1）原理" class="headerlink" title="（1）原理"></a>（1）原理</h5><p><img src="../images/fruit_pretrain_net.png" alt="原理图"><br>上图摘自《Python深度学习》，原理就是使用vgg16作为训练好的卷积基，然后将其冻结，防止在训练过程中，内部参数被改变；在其上添加我们自己的全连接层，作为新的分类器，然后开始训练</p>
<h5 id="（2）获取卷积基"><a href="#（2）获取卷积基" class="headerlink" title="（2）获取卷积基"></a>（2）获取卷积基</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conv_base  = keras.applications.vgg16.VGG16(</span><br><span class="line">    weights=<span class="string">"imagenet"</span>,</span><br><span class="line">    include_top=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>keras中自带了一些常用模型，其中就包括vgg16。<code>include_top</code>指是否需要包括vgg16的全连接层，由于它的全连接层有1000个类别的输出，而我们这里只有5个类别，所以并不需要</p>
<h5 id="（3）执行冻结"><a href="#（3）执行冻结" class="headerlink" title="（3）执行冻结"></a>（3）执行冻结</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conv_base.trainable = <span class="literal">False</span></span><br><span class="line">print(<span class="string">"This is the number of trainable weights "</span></span><br><span class="line">      <span class="string">"after freezing the conv base:"</span>, len(conv_base.trainable_weights)) <span class="comment"># 0</span></span><br></pre></td></tr></table></figure>

<h5 id="（4）模型构建"><a href="#（4）模型构建" class="headerlink" title="（4）模型构建"></a>（4）模型构建</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">  <span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">  inputs = keras.Input(shape=(<span class="number">180</span>, <span class="number">180</span>, <span class="number">3</span>))</span><br><span class="line">  x = data_augmentation(inputs)</span><br><span class="line"><span class="comment"># x = layers.Rescaling(1./255)(x)</span></span><br><span class="line">  x = keras.applications.vgg16.preprocess_input(x)</span><br><span class="line">  x = conv_base(x)</span><br><span class="line"><span class="comment"># x = layers.Conv2D(filters=32, kernel_size=3, activation="relu")(x)</span></span><br><span class="line"><span class="comment"># x = layers.MaxPooling2D(pool_size=2)(x)</span></span><br><span class="line"><span class="comment"># x = layers.Dropout(0.5)(x)</span></span><br><span class="line"><span class="comment"># x = layers.Conv2D(filters=64, kernel_size=3, activation="relu")(x)</span></span><br><span class="line"><span class="comment"># x = layers.MaxPooling2D(pool_size=2)(x)</span></span><br><span class="line"><span class="comment"># x = layers.Dropout(0.5)(x)</span></span><br><span class="line"><span class="comment"># x = layers.Conv2D(filters=128, kernel_size=3, activation="relu")(x)</span></span><br><span class="line"><span class="comment"># x = layers.MaxPooling2D(pool_size=2)(x)</span></span><br><span class="line"><span class="comment"># x = layers.Dropout(0.5)(x)</span></span><br><span class="line">  x = layers.Flatten()(x)</span><br><span class="line">  x = layers.Dense(<span class="number">512</span>, activation=<span class="string">"relu"</span>)(x)</span><br><span class="line">  x = layers.Dropout(<span class="number">0.5</span>)(x)</span><br><span class="line">  outputs = layers.Dense(<span class="number">5</span>, activation=<span class="string">"softmax"</span>)(x)</span><br><span class="line">  model = keras.Model(inputs=inputs, outputs=outputs)</span><br></pre></td></tr></table></figure>
<p>使用vgg16对输入数据格式有要求，可以调用<code>keras.applications.vgg16.preprocess_input</code>来处理，tf官方也给出了说明（如下图）<br><img src="../images/vgg16_input.png" alt="vgg16 input说明"></p>
<h5 id="（5）训练与评估"><a href="#（5）训练与评估" class="headerlink" title="（5）训练与评估"></a>（5）训练与评估</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">    train_ds,</span><br><span class="line">    epochs=<span class="number">50</span>,</span><br><span class="line">    validation_data=val_ds,</span><br><span class="line">    callbacks=callbacks)</span><br></pre></td></tr></table></figure>
<p>依旧是跑50轮，自动保存最佳模型，结果如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/50</span><br><span class="line">33/33 [==============================] - 5s 121ms/step - loss: 8.9553 - accuracy: 0.8488 - val_loss: 5.7501 - val_accuracy: 0.8516</span><br><span class="line">Epoch 2/50</span><br><span class="line">33/33 [==============================] - 4s 117ms/step - loss: 1.6742 - accuracy: 0.9483 - val_loss: 0.0697 - val_accuracy: 0.9922</span><br><span class="line">Epoch 3/50</span><br><span class="line">33/33 [==============================] - 4s 120ms/step - loss: 1.3791 - accuracy: 0.9522 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 4/50</span><br><span class="line">33/33 [==============================] - 4s 111ms/step - loss: 0.8950 - accuracy: 0.9703 - val_loss: 0.1849 - val_accuracy: 0.9844</span><br><span class="line">Epoch 5/50</span><br><span class="line">33/33 [==============================] - 4s 110ms/step - loss: 0.6955 - accuracy: 0.9732 - val_loss: 5.3784e-06 - val_accuracy: 1.0000</span><br><span class="line">Epoch 6/50</span><br><span class="line">33/33 [==============================] - 4s 112ms/step - loss: 0.7686 - accuracy: 0.9675 - val_loss: 1.8626e-09 - val_accuracy: 1.0000</span><br><span class="line">Epoch 7/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.5589 - accuracy: 0.9789 - val_loss: 1.3970e-07 - val_accuracy: 1.0000</span><br><span class="line">Epoch 8/50</span><br><span class="line">33/33 [==============================] - 4s 108ms/step - loss: 0.6402 - accuracy: 0.9770 - val_loss: 0.0020 - val_accuracy: 1.0000</span><br><span class="line">Epoch 9/50</span><br><span class="line">33/33 [==============================] - 4s 110ms/step - loss: 0.4821 - accuracy: 0.9923 - val_loss: 1.2935 - val_accuracy: 0.9844</span><br><span class="line">Epoch 10/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.6913 - accuracy: 0.9789 - val_loss: 0.1530 - val_accuracy: 0.9844</span><br><span class="line">Epoch 11/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.2504 - accuracy: 0.9885 - val_loss: 1.7731e-04 - val_accuracy: 1.0000</span><br><span class="line">Epoch 12/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.1919 - accuracy: 0.9933 - val_loss: 0.0678 - val_accuracy: 0.9922</span><br><span class="line">Epoch 13/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.3878 - accuracy: 0.9895 - val_loss: 0.5037 - val_accuracy: 0.9844</span><br><span class="line">Epoch 14/50</span><br><span class="line">33/33 [==============================] - 4s 105ms/step - loss: 0.5507 - accuracy: 0.9876 - val_loss: 0.1472 - val_accuracy: 0.9922</span><br><span class="line">Epoch 15/50</span><br><span class="line">33/33 [==============================] - 4s 114ms/step - loss: 0.5431 - accuracy: 0.9866 - val_loss: 0.4348 - val_accuracy: 0.9922</span><br><span class="line">Epoch 16/50</span><br><span class="line">33/33 [==============================] - 4s 105ms/step - loss: 0.3337 - accuracy: 0.9895 - val_loss: 0.7943 - val_accuracy: 0.9922</span><br><span class="line">Epoch 17/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.3115 - accuracy: 0.9885 - val_loss: 0.0187 - val_accuracy: 0.9922</span><br><span class="line">Epoch 18/50</span><br><span class="line">33/33 [==============================] - 4s 114ms/step - loss: 0.1026 - accuracy: 0.9943 - val_loss: 0.0096 - val_accuracy: 0.9922</span><br><span class="line">Epoch 19/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.1187 - accuracy: 0.9923 - val_loss: 3.4478e-05 - val_accuracy: 1.0000</span><br><span class="line">Epoch 20/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.2564 - accuracy: 0.9914 - val_loss: 0.2398 - val_accuracy: 0.9922</span><br><span class="line">Epoch 21/50</span><br><span class="line">33/33 [==============================] - 4s 115ms/step - loss: 0.0961 - accuracy: 0.9933 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 22/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.2745 - accuracy: 0.9943 - val_loss: 3.7253e-09 - val_accuracy: 1.0000</span><br><span class="line">Epoch 23/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.2143 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 24/50</span><br><span class="line">33/33 [==============================] - 4s 116ms/step - loss: 0.2618 - accuracy: 0.9914 - val_loss: 2.7008e-08 - val_accuracy: 1.0000</span><br><span class="line">Epoch 25/50</span><br><span class="line">33/33 [==============================] - 4s 108ms/step - loss: 0.0689 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 26/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.2700 - accuracy: 0.9952 - val_loss: 0.5954 - val_accuracy: 0.9844</span><br><span class="line">Epoch 27/50</span><br><span class="line">33/33 [==============================] - 4s 108ms/step - loss: 0.0642 - accuracy: 0.9971 - val_loss: 0.0012 - val_accuracy: 1.0000</span><br><span class="line">Epoch 28/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.0589 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 29/50</span><br><span class="line">33/33 [==============================] - 4s 114ms/step - loss: 0.2216 - accuracy: 0.9952 - val_loss: 0.0026 - val_accuracy: 1.0000</span><br><span class="line">Epoch 30/50</span><br><span class="line">33/33 [==============================] - 4s 118ms/step - loss: 0.2171 - accuracy: 0.9933 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 31/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 32/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.1920 - accuracy: 0.9943 - val_loss: 9.3132e-10 - val_accuracy: 1.0000</span><br><span class="line">Epoch 33/50</span><br><span class="line">33/33 [==============================] - 4s 117ms/step - loss: 0.1269 - accuracy: 0.9943 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 34/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.2172 - accuracy: 0.9943 - val_loss: 2.7940e-09 - val_accuracy: 1.0000</span><br><span class="line">Epoch 35/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.0248 - accuracy: 0.9971 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 36/50</span><br><span class="line">33/33 [==============================] - 4s 110ms/step - loss: 0.0794 - accuracy: 0.9971 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 37/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.1331 - accuracy: 0.9943 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 38/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 6.6318e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 39/50</span><br><span class="line">33/33 [==============================] - 4s 108ms/step - loss: 0.1238 - accuracy: 0.9952 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 40/50</span><br><span class="line">33/33 [==============================] - 4s 108ms/step - loss: 0.0394 - accuracy: 0.9952 - val_loss: 2.7940e-09 - val_accuracy: 1.0000</span><br><span class="line">Epoch 41/50</span><br><span class="line">33/33 [==============================] - 4s 106ms/step - loss: 0.0162 - accuracy: 0.9981 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 42/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.1025 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 43/50</span><br><span class="line">33/33 [==============================] - 4s 118ms/step - loss: 0.2053 - accuracy: 0.9981 - val_loss: 3.0987e-05 - val_accuracy: 1.0000</span><br><span class="line">Epoch 44/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.1768 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 45/50</span><br><span class="line">33/33 [==============================] - 4s 114ms/step - loss: 8.4492e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 46/50</span><br><span class="line">33/33 [==============================] - 4s 109ms/step - loss: 0.1554 - accuracy: 0.9943 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 47/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.1252 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 48/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 0.1492 - accuracy: 0.9962 - val_loss: 0.0880 - val_accuracy: 0.9922</span><br><span class="line">Epoch 49/50</span><br><span class="line">33/33 [==============================] - 4s 116ms/step - loss: 0.1301 - accuracy: 0.9962 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br><span class="line">Epoch 50/50</span><br><span class="line">33/33 [==============================] - 4s 107ms/step - loss: 2.5325e-08 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000</span><br></pre></td></tr></table></figure>
<p>loss和accuracy曲线：<br><img src="../images/fruit_history_3.png" alt="loss和accuracy曲线"><br>绝了，一个顶天一个立地（哈哈～），希望有生之年还能见到这样美妙的情景</p>
<p>最后，加载一下最佳模型，执行预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_model = keras.models.load_model(<span class="string">"fruits_vgg16_with_aug.h5"</span>)</span><br><span class="line">test_loss, test_acc = test_model.evaluate(test_ds)</span><br><span class="line">print(<span class="string">f"Test accuracy: <span class="subst">&#123;test_acc:<span class="number">.3</span>f&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<p>结果：1.00</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">5/5 [==============================] - 2s 430ms/step - loss: 2.4407e-05 - accuracy: 1.0000</span><br><span class="line">Test accuracy: 1.000</span><br></pre></td></tr></table></figure>
<p>分类报告如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       1.00      1.00      1.00        28</span><br><span class="line">           1       1.00      1.00      1.00        27</span><br><span class="line">           2       1.00      1.00      1.00        23</span><br><span class="line">           3       1.00      1.00      1.00        31</span><br><span class="line">           4       1.00      1.00      1.00        24</span><br><span class="line"></span><br><span class="line">    accuracy                           1.00       133</span><br><span class="line">   macro avg       1.00      1.00      1.00       133</span><br><span class="line">weighted avg       1.00      1.00      1.00       133</span><br></pre></td></tr></table></figure>
<p>这就是使用预训练模型的效果，杀鸡用牛刀，满分！</p>
<h3 id="四、实验中遇到的问题"><a href="#四、实验中遇到的问题" class="headerlink" title="四、实验中遇到的问题"></a>四、实验中遇到的问题</h3><h4 id="1-报错：Input-0-of-layer-“model”-is-incompatible-with-the-layer-expected-shape-None-180-180-3-found-shape-256-256-3"><a href="#1-报错：Input-0-of-layer-“model”-is-incompatible-with-the-layer-expected-shape-None-180-180-3-found-shape-256-256-3" class="headerlink" title="1.报错：Input 0 of layer “model” is incompatible with the layer: expected shape=(None, 180, 180, 3), found shape=(256, 256, 3)"></a>1.报错：Input 0 of layer “model” is incompatible with the layer: expected shape=(None, 180, 180, 3), found shape=(256, 256, 3)</h4><p>原因：输入模型的图片数据shape与定义的shape不符</p>
<p>解决：在使用<code>image_dataset_from_directory</code>转换dataset时，是可以直接定义image_size的，这样很方便</p>
<h4 id="2-刚开始使用vgg16时，发现训练中loss不下降"><a href="#2-刚开始使用vgg16时，发现训练中loss不下降" class="headerlink" title="2.刚开始使用vgg16时，发现训练中loss不下降"></a>2.刚开始使用vgg16时，发现训练中loss不下降</h4><p>原因：《Python深度学习》这本书中，关于训练中常见的一些问题，都提供了很详实的原因和解决方案。对于这种情况，通常是训练的配置有问题</p>
<p>解决：查了下vgg16的<code>preprocess_input</code>方法，文档中对输入要求为：<code>A floating point numpy.array or a tf.Tensor, 3D or 4D with 3 color channels, with values in the range [0, 255]</code>，所以Rescaling层并不需要，需要注释掉</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inputs = keras.Input(shape=(<span class="number">180</span>, <span class="number">180</span>, <span class="number">3</span>))</span><br><span class="line">x = data_augmentation(inputs)</span><br><span class="line"><span class="comment"># x = layers.Rescaling(1./255)(x)</span></span><br><span class="line">x = keras.applications.vgg16.preprocess_input(x)</span><br></pre></td></tr></table></figure>

<h4 id="3-colab跑epoch时很慢"><a href="#3-colab跑epoch时很慢" class="headerlink" title="3.colab跑epoch时很慢"></a>3.colab跑epoch时很慢</h4><p>原因：一开始以为是显卡不给力，还额外买了点算力，但问题依旧，后来想到可能是因为数据集放在了google drive上的原因，因为dataset是generator，是惰性读取，并不会一次性将数据读入内存，训练时还是会和磁盘有交互</p>
<p>解决：将数据集搬到实验环境的本地磁盘上</p>
<h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3><p>整个实验是一个标准的图像多分类问题，在深度学习中是比较基础、入门的内容。实验先是构建了一个初始的模型，然后针对数据集较小的问题，使用数据增强来提升数据多样性，从而优化了模型精度。在此基础上，又尝试了vgg16，见证了预训练模型的强大之处。</p>
<p>其实，《Python深度学习》中还介绍了对预训练模型的fine tune，但是考虑到data augmentation + vgg16的accuracy已经到1.0了，就没有再尝试。</p>
<p>多实践多总结，相信“日拱一卒，功不唐捐”</p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/CNN/" rel="tag"><i class="fa fa-tag"></i> CNN</a>
              <a href="/tags/%E6%A8%A1%E5%9E%8B%E8%B0%83%E4%BC%98/" rel="tag"><i class="fa fa-tag"></i> 模型调优</a>
              <a href="/tags/keras/" rel="tag"><i class="fa fa-tag"></i> keras</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/mysql-basic/" rel="prev" title="MySQL 基础操作">
      <i class="fa fa-chevron-left"></i> MySQL 基础操作
    </a></div>
      <div class="post-nav-item">
    <a href="/object-detection-faster-rcnn/" rel="next" title="目标检测之Faster R-CNN原理">
      目标检测之Faster R-CNN原理 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#一、任务描述"><span class="nav-text">一、任务描述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二、实验过程"><span class="nav-text">二、实验过程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-数据准备"><span class="nav-text">1.数据准备</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）将图片转为dataset"><span class="nav-text">（1）将图片转为dataset</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）划分测试集"><span class="nav-text">（2）划分测试集</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-模型构建与训练"><span class="nav-text">2.模型构建与训练</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）构建"><span class="nav-text">（1）构建</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）编译"><span class="nav-text">（2）编译</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（3）训练"><span class="nav-text">（3）训练</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-评估与预测"><span class="nav-text">3.评估与预测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）绘制loss和accuracy曲线"><span class="nav-text">（1）绘制loss和accuracy曲线</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）预测并获取分类报告"><span class="nav-text">（2）预测并获取分类报告</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三、模型调优"><span class="nav-text">三、模型调优</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-数据增强（data-augmentation）"><span class="nav-text">1.数据增强（data augmentation）</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）添加数据增强层"><span class="nav-text">（1）添加数据增强层</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）重新构建模型"><span class="nav-text">（2）重新构建模型</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（3）使用callback函数"><span class="nav-text">（3）使用callback函数</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（4）训练与评估"><span class="nav-text">（4）训练与评估</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-使用预训练模型"><span class="nav-text">2.使用预训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#（1）原理"><span class="nav-text">（1）原理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（2）获取卷积基"><span class="nav-text">（2）获取卷积基</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（3）执行冻结"><span class="nav-text">（3）执行冻结</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（4）模型构建"><span class="nav-text">（4）模型构建</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#（5）训练与评估"><span class="nav-text">（5）训练与评估</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#四、实验中遇到的问题"><span class="nav-text">四、实验中遇到的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-报错：Input-0-of-layer-“model”-is-incompatible-with-the-layer-expected-shape-None-180-180-3-found-shape-256-256-3"><span class="nav-text">1.报错：Input 0 of layer “model” is incompatible with the layer: expected shape&#x3D;(None, 180, 180, 3), found shape&#x3D;(256, 256, 3)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-刚开始使用vgg16时，发现训练中loss不下降"><span class="nav-text">2.刚开始使用vgg16时，发现训练中loss不下降</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-colab跑epoch时很慢"><span class="nav-text">3.colab跑epoch时很慢</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#五、总结"><span class="nav-text">五、总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="roubin"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">roubin</p>
  <div class="site-description" itemprop="description">芝兰其室，金石其心<br/>仁义为友，道德为师</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">143</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">84</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/satorioh" title="GitHub → https://github.com/satorioh" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wangbinxp@gmail.com" title="E-Mail → mailto:wangbinxp@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2015 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">roubin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://roubinme.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "https://roubin.me/fruit-classification-model-optimization-exercise/";
    this.page.identifier = "fruit-classification-model-optimization-exercise/";
    this.page.title = "基于CNN的水果分类与模型调优实验";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://roubinme.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
